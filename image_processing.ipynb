{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9WGtISjBxE7"
   },
   "source": [
    "## SUV (Standard Uptake Value) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDzFV0pZB2VL"
   },
   "outputs": [],
   "source": [
    "# extract half life and start time from header\n",
    "RefDs = dicom.read_file(lstFilesDCM[0], force=True)\n",
    "\n",
    "radSeq = RefDs.RadiopharmaceuticalInformationSequence\n",
    "halfLife = float(radSeq[0]['RadionuclideHalfLife'].value) #seconds\n",
    "startScan = radSeq[0]['RadiopharmaceuticalStartDateTime'].value\n",
    "startScan = startScan[:-5]\n",
    "startScan = datetime.strptime(startScan, '%Y%m%d%H%M%S')\n",
    "\n",
    "print(startScan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3KoEMCKB4NE"
   },
   "outputs": [],
   "source": [
    "# receive input (dose 1, time 1, dose 2, time 2, weight)\n",
    "print('Enter syringe 1 dose amount (MBq): ')\n",
    "dose1 = float(input())\n",
    "\n",
    "print ('Enter syringe 1 start time (YYYY-MM-DD hh:mm): ')\n",
    "start1 = input()\n",
    "start1 = datetime.strptime(start1, '%Y-%m-%d %H:%M')\n",
    "\n",
    "print('Enter syringe 2 dose amount (MBq): ')\n",
    "dose2 = float(input())\n",
    "\n",
    "print ('Enter syringe 2 start time (YYYY-MM-DD hh:mm): ')\n",
    "start2 = input()\n",
    "start2 = datetime.strptime(start2, '%Y-%m-%d %H:%M')\n",
    "\n",
    "print ('Enter body weight (g): ')\n",
    "weight = float(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rY4Qs9AuB5fR"
   },
   "outputs": [],
   "source": [
    "# calculate decay correction\n",
    "# all time in minutes, doses in MBq\n",
    "\n",
    "halfLifeMin = halfLife / 60 #halfLife seconds to minutes\n",
    "timeDiff1o = start1 - startScan\n",
    "timeDiff1 = np.abs(int(timeDiff1o.total_seconds() / 60)) #take negative or absolute?\n",
    "timeDiff1n = int(timeDiff1o.total_seconds() / 60)\n",
    "timeDiff2 = start2 - startScan\n",
    "timeDiff2 = int(timeDiff2.total_seconds() / 60)\n",
    "\n",
    "decayConst = np.log(2)/halfLifeMin\n",
    "\n",
    "D1 = dose1 * np.exp((decayConst * -1) * (timeDiff1n))\n",
    "D2 = dose2 * np.exp(decayConst * (timeDiff2))\n",
    "\n",
    "decayCorr = D1 - D2\n",
    "\n",
    "ArrayMBq = og_arr / 1000 #ArrayDicom is in kBq/cc. change to MBq/cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWTP72nLB8Fb"
   },
   "outputs": [],
   "source": [
    "# calculate SUV\n",
    " \n",
    "ArraySUV = ArrayMBq / (decayCorr / weight)\n",
    "#print(decayCorr/weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9EaEMNQCBIp"
   },
   "outputs": [],
   "source": [
    "f,axarr = plt.subplots(1,2)\n",
    "a = axarr[0].imshow(ArraySUV[:,:,70,20], vmin=0,vmax=1.6)\n",
    "b = axarr[1].imshow(ans_suv_arr[:,:,70,20],vmin=0,vmax=1.6)\n",
    "plt.colorbar(a,cax=f.add_axes([0.92,0.2,0.02,0.6]))\n",
    "plt.title('Calculated SUV Slice vs. Original SUV Slice', horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yH9jWc7wCBmp"
   },
   "outputs": [],
   "source": [
    "suv_wb_nii = nb.Nifti1Image(ArraySUV, og_image.affine)\n",
    "print(suv_wb_nii.shape) # test\n",
    "suv_wb_nii_first = image.index_img(suv_wb_nii, 20) # visualize one instance\n",
    "print(suv_wb_nii_first.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-iZFDid4mpah"
   },
   "outputs": [],
   "source": [
    "# Saver\n",
    "\n",
    "print('Save? (Y/N): ')\n",
    "inp = input().capitalize()\n",
    "if inp =='Y':\n",
    "  suv_name = sample_og_name.replace('PET', 'PET_SUV')\n",
    "  nb.save(suv_wb_nii, rslt_pth + suv_name)\n",
    "  print(suv_name + 'saved in ' + rslt_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmIGX0QUmp_4"
   },
   "outputs": [],
   "source": [
    "# visualize\n",
    "\n",
    "plotting.plot_stat_map(suv_br_nii_first, bg_img=False, colorbar=True, cmap='Spectral', black_bg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXQzTY64bRkA"
   },
   "source": [
    "# PET Scan Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGz-ZTXSEp0f"
   },
   "outputs": [],
   "source": [
    "# set Answer PATHs\n",
    "\n",
    "sample_og_name = '20201111_WB_No1_FDG_PET.nii'\n",
    "sample_og = ans_pth + sample_og_name\n",
    "ans_suv = ans_pth + '20201111_WB_No1_FDG_PET_SUV.nii'\n",
    "ans_avg = ans_pth + '20201111_WB_No1_FDG_PET_avg40-90min.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "966QFLdf-_da"
   },
   "outputs": [],
   "source": [
    "# READ .NII FILES AND DICOM HEADERS\n",
    "og_image = nb.load(sample_og) #original nii file\n",
    "og_arr = np.array(og_image.dataobj)\n",
    "\n",
    "ans_suv_im = nb.load(ans_suv) #suv nii file\n",
    "ans_suv_arr = np.array(ans_suv_im.dataobj)\n",
    "\n",
    "ans_avg_im = nb.load(ans_avg) #40-90min avg nii file\n",
    "ans_avg_im_squeezed = nb.squeeze_image(ans_avg_im) # truncate curtailing 1\n",
    "ans_avg_arr = np.array(ans_avg_im_squeezed.dataobj)\n",
    "\n",
    "print('og_arr:', og_arr.shape)\n",
    "print('ans_suv_arr:', ans_suv_arr.shape)\n",
    "print('ans_avg_arr:', ans_avg_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOgtUG7o_num"
   },
   "outputs": [],
   "source": [
    "# put all .dcm files in Path into lstFilesDCM\n",
    "\n",
    "PathDicom = pet_pth\n",
    "lstFilesDCM = []  # create an empty list\n",
    "for dirName, subdirList, fileList in os.walk(PathDicom):\n",
    "    for filename in fileList:\n",
    "      #if \"._\" in filename.lower():   # remove ghost files if existant\n",
    "        #os.remove(PathDicom + )\n",
    "      \n",
    "      if \"._\" not in filename.lower():  # check whether the file's DICOM. In our case, none DICOM files start in '._'   \n",
    "        lstFilesDCM.append(os.path.join(dirName,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5WPWM8_G9Vg"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "len(lstFilesDCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTqKOYfQ_p_E"
   },
   "outputs": [],
   "source": [
    "# Get ref file\n",
    "RefDs = dicom.read_file(lstFilesDCM[0], force=True)\n",
    "\n",
    "# Load dimensions based on the number of rows, columns, and slices (along the Z axis)\n",
    "ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM))\n",
    "\n",
    "# Load spacing values (in mm)\n",
    "ConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))\n",
    "\n",
    "x = np.arange(0.0, (ConstPixelDims[0]+1)*ConstPixelSpacing[0], ConstPixelSpacing[0])\n",
    "y = np.arange(0.0, (ConstPixelDims[1]+1)*ConstPixelSpacing[1], ConstPixelSpacing[1])\n",
    "z = np.arange(0.0, (RefDs.NumberOfSlices+1)*ConstPixelSpacing[2], ConstPixelSpacing[2])\n",
    "t = RefDs.NumberOfTimeSlices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2oU5uViIgcJ"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "len(RefDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7FXjN8d_uae"
   },
   "outputs": [],
   "source": [
    "# time(ms) array\n",
    "time2dur = {}\n",
    "imgPosZ = np.zeros(len(lstFilesDCM))\n",
    "refTime = np.zeros(len(lstFilesDCM))\n",
    "slopes = np.zeros(len(lstFilesDCM))\n",
    "\n",
    "# initialize pixel arrays\n",
    "RawDicom = np.zeros((len(x)-1, len(y)-1, RefDs.NumberOfSlices,t))\n",
    "RSDicom = np.zeros((len(x)-1, len(y)-1, RefDs.NumberOfSlices,t))\n",
    "\n",
    "# iterate over dicom files and collect needed header & pixel data\n",
    "for i in range(len(lstFilesDCM)):\n",
    "  currRef = dicom.read_file(lstFilesDCM[i], force=True)\n",
    "  \n",
    "  # Store z position, reference time, frame duration\n",
    "  imgPosZ[i] = currRef.ImagePositionPatient[2]\n",
    "  refTime[i] = currRef.FrameReferenceTime\n",
    "  time2dur[currRef.FrameReferenceTime] = currRef.ActualFrameDuration\n",
    "  slopes[i] = currRef.RescaleSlope\n",
    "\n",
    "zVals = np.unique(imgPosZ) #These are all of the z axis positions. There are 163\n",
    "tVals = np.unique(refTime) #There are all of the time frames. There are 41\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VOyCC70IX9F"
   },
   "outputs": [],
   "source": [
    "# test: check outputs\n",
    "\n",
    "print('zVals:', zVals.shape)\n",
    "print('tVals:', tVals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns-Kb3Ji_vWN"
   },
   "outputs": [],
   "source": [
    "RawDicom = np.zeros((len(x)-1, len(y)-1, RefDs.NumberOfSlices,t))\n",
    "RSDicom = np.zeros((len(x)-1, len(y)-1, RefDs.NumberOfSlices,t))\n",
    "\n",
    "# iterate again for pixel arrays\n",
    "for i in range(len(lstFilesDCM)):\n",
    "  currRef = dicom.read_file(lstFilesDCM[i], force=True)\n",
    "  \n",
    "  #find z position and reference time\n",
    "  currZ = int(np.where(zVals==currRef.ImagePositionPatient[2])[0])\n",
    "  currT = int(np.where(tVals == currRef.FrameReferenceTime)[0][0])\n",
    "\n",
    "  # Get pixel data and rescale it with slope\n",
    "  RawDicom[:,:,currZ, currT] = currRef.pixel_array\n",
    "  RSDicom[:, :, currZ, currT] = currRef.pixel_array / float(currRef.RescaleSlope)\n",
    "\n",
    "# This is where I tried to \n",
    "rsArrayDicom = np.transpose(RSDicom, (1,0,2,3))\n",
    "ArrayDicom = np.transpose(RawDicom, (1,0,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCm8SPwo1NQB"
   },
   "outputs": [],
   "source": [
    "# test output\n",
    "\n",
    "print('rsArrayDicom:', rsArrayDicom.shape)\n",
    "print('RescaleSlope:', currRef.RescaleSlope)\n",
    "print('ArrayDicom:', ArrayDicom.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tPIsTGh_ztB"
   },
   "outputs": [],
   "source": [
    "# # use only if RescaleSlope is NOT 1\n",
    "\n",
    "# f,axarr = plt.subplots(1,2)\n",
    "# a = axarr[0].imshow(rsArrayDicom[:,:,60,20], vmin=0,vmax=500)\n",
    "# b = axarr[1].imshow(og_arr[:,:,60,20],vmin=0,vmax=500)\n",
    "# plt.colorbar(a,cax=f.add_axes([0.92,0.2,0.02,0.6]))\n",
    "# #plt.subplots_adjust(left=0,right=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vp_E-MgfBKHc"
   },
   "outputs": [],
   "source": [
    "#Receive input for frames\n",
    "print('Enter start frame (0 to',len(tVals)-1 , 'available): ')\n",
    "frame1 = int(input())\n",
    "\n",
    "print('Enter end frame (0 to',len(tVals)-1 , 'available): ')\n",
    "frame2 = int(input())\n",
    "print('Calculating frames',frame1,'to',frame2,'(inclusive)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MTA2g_8BgHK"
   },
   "outputs": [],
   "source": [
    "# all time is in s\n",
    "summed_arr = np.zeros(og_arr.shape[0:3])\n",
    "sum_dur = 0\n",
    "sum_dur_list = []\n",
    "\n",
    "for i in np.arange(frame1, frame2+1):\n",
    "  frameDuration = int(time2dur[tVals[i]])/1000\n",
    "  summed_arr += (og_arr[:,:,:,i] * frameDuration)\n",
    "  sum_dur += frameDuration\n",
    "  sum_dur_list.append(sum_dur)\n",
    "\n",
    "avg_arr = summed_arr / sum_dur\n",
    "\n",
    "print('sum_dur_list:', sum_dur_list)\n",
    "print('avg_arr:', avg_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcP-0I_fBuP3"
   },
   "outputs": [],
   "source": [
    "f,axarr = plt.subplots(1,2)\n",
    "a = axarr[0].imshow(avg_arr[:,:,60], vmin=0,vmax=550)\n",
    "b = axarr[1].imshow(ans_avg_arr[:,:,60,0],vmin=0,vmax=550)\n",
    "plt.colorbar(a,cax=f.add_axes([0.92,0.2,0.02,0.6]))\n",
    "plt.title('Calculated Average Slice vs. Original Average Slice', horizontalalignment='right')\n",
    "#plt.subplots_adjust(left=0,right=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C05vpuGLBwQ8"
   },
   "outputs": [],
   "source": [
    "# convert Numpy array --> Nifti\n",
    "avg_nii = nb.Nifti1Image(avg_arr, og_image.affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xxiDQo5lFa0"
   },
   "outputs": [],
   "source": [
    "# Saver\n",
    "\n",
    "print('Save? (Y/N): ')\n",
    "inp = input().capitalize()\n",
    "if inp =='Y':\n",
    "  avg_name = sample_og_name.replace('PET', 'PET_avg40-90min')\n",
    "  nb.save(avg_nii, rslt_pth + avg_name)\n",
    "  print(avg_name + 'saved in ' + rslt_pth)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "plaintext"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
